{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import xgboost as xgb\n",
    "from time import time\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the train data is (1023191, 14)\n",
      "Shape of the test data is (773858, 12)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'len_train = len(train_df)\\ntrain_df = train_df.append(test_df)\\ndel test_df\\ngc.collect()'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#path = '/Users/804357/Desktop/MyFiles/Learn/LOM/Data/'\n",
    "path = '/Users/Vishy/Files/AVDatahack/LOM/Data/' \n",
    "train = pd.read_csv(path+'train.csv')\n",
    "test = pd.read_csv(path+'test.csv')\n",
    "camp = pd.read_csv(path+'campaign_data.csv')\n",
    "\n",
    "train_df = pd.merge(train, camp, on='campaign_id')\n",
    "test_df = pd.merge(test, camp, on='campaign_id')\n",
    "print('Shape of the train data is', train_df.shape)\n",
    "print('Shape of the test data is', test_df.shape)\n",
    "\n",
    "\"\"\"len_train = len(train_df)\n",
    "train_df = train_df.append(test_df)\n",
    "del test_df\n",
    "gc.collect()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New variable creations\n"
     ]
    }
   ],
   "source": [
    "print('New variable creations')\n",
    "train_df['hour'] = pd.to_datetime(train_df.send_date).dt.hour.astype('uint8')\n",
    "train_df['day'] = pd.to_datetime(train_df.send_date).dt.day.astype('uint8')\n",
    "train_df['dow'] = pd.to_datetime(train_df.send_date).dt.dayofweek.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['dow'] = train_df['dow'].map({0:'Mon', 1:'Tue', 2:'Wed', 3:'Thr',4: 'Fri', 5: 'Sat', 6: 'Sun'} ).astype(str)\n",
    "train_df['hour'] = train_df['hour'].map({0:'AM1', 1:'AM1', 2:'AM1', 3:'AM2', 4:'AM2', 5:'AM2', 6:'AM3', 7:'AM3', 8:'AM3',\n",
    "                                         9:'AM4', 10:'AM4', 11:'AM4', 12:'PM1', 13:'PM1', 14:'PM1', 15:'PM2', 16:'PM2',\n",
    "                                         17:'PM2', 18:'PM3', 19:'PM3', 20:'PM3', 21:'PM4', 22:'PM4', 23:'PM4'}).astype(str)\n",
    "train_df['day'] = train_df['day'].map({1:'VEAR', 2:'VEAR', 3:'VEAR', 4:'VEAR', 5:'VEAR', 6:'EAR', 7:'EAR', 8:'EAR',\n",
    "                                       9:'EAR', 10:'EAR', 11:'MID', 12:'MID', 13:'MID', 14:'MID', 15:'MID', 16:'VMID',\n",
    "                                       17:'VMID', 18:'VMID', 19:'VMID', 20:'VMID', 21:'LAT', 22:'LAT', 23:'LAT', \n",
    "                                       24:'LAT', 25:'LAT', 26:'VLAT', 27:'VLAT', 28:'VLAT', 29:'VLAT', 30:'VLAT',\n",
    "                                       31:'VLAT'}).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>send_date</th>\n",
       "      <th>is_open</th>\n",
       "      <th>is_click</th>\n",
       "      <th>communication_type</th>\n",
       "      <th>total_links</th>\n",
       "      <th>no_of_internal_links</th>\n",
       "      <th>no_of_images</th>\n",
       "      <th>no_of_sections</th>\n",
       "      <th>email_body</th>\n",
       "      <th>subject</th>\n",
       "      <th>email_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42_14051</td>\n",
       "      <td>14051</td>\n",
       "      <td>42</td>\n",
       "      <td>01-09-2017 19:55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Newsletter</td>\n",
       "      <td>88</td>\n",
       "      <td>79</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>September Newsletter\\r\\n \\r\\nDear AVians,\\r\\n ...</td>\n",
       "      <td>[September] Exciting days ahead with DataHack ...</td>\n",
       "      <td>http://r.newsletters.analyticsvidhya.com/7v3rd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42_177808</td>\n",
       "      <td>177808</td>\n",
       "      <td>42</td>\n",
       "      <td>01-09-2017 20:13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Newsletter</td>\n",
       "      <td>88</td>\n",
       "      <td>79</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>September Newsletter\\r\\n \\r\\nDear AVians,\\r\\n ...</td>\n",
       "      <td>[September] Exciting days ahead with DataHack ...</td>\n",
       "      <td>http://r.newsletters.analyticsvidhya.com/7v3rd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42_133077</td>\n",
       "      <td>133077</td>\n",
       "      <td>42</td>\n",
       "      <td>01-09-2017 20:11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Newsletter</td>\n",
       "      <td>88</td>\n",
       "      <td>79</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>September Newsletter\\r\\n \\r\\nDear AVians,\\r\\n ...</td>\n",
       "      <td>[September] Exciting days ahead with DataHack ...</td>\n",
       "      <td>http://r.newsletters.analyticsvidhya.com/7v3rd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42_118677</td>\n",
       "      <td>118677</td>\n",
       "      <td>42</td>\n",
       "      <td>01-09-2017 20:15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Newsletter</td>\n",
       "      <td>88</td>\n",
       "      <td>79</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>September Newsletter\\r\\n \\r\\nDear AVians,\\r\\n ...</td>\n",
       "      <td>[September] Exciting days ahead with DataHack ...</td>\n",
       "      <td>http://r.newsletters.analyticsvidhya.com/7v3rd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42_25809</td>\n",
       "      <td>25809</td>\n",
       "      <td>42</td>\n",
       "      <td>01-09-2017 19:49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Newsletter</td>\n",
       "      <td>88</td>\n",
       "      <td>79</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>September Newsletter\\r\\n \\r\\nDear AVians,\\r\\n ...</td>\n",
       "      <td>[September] Exciting days ahead with DataHack ...</td>\n",
       "      <td>http://r.newsletters.analyticsvidhya.com/7v3rd...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  user_id  campaign_id         send_date  is_open  is_click  \\\n",
       "0   42_14051    14051           42  01-09-2017 19:55        0         0   \n",
       "1  42_177808   177808           42  01-09-2017 20:13        0         0   \n",
       "2  42_133077   133077           42  01-09-2017 20:11        0         0   \n",
       "3  42_118677   118677           42  01-09-2017 20:15        0         0   \n",
       "4   42_25809    25809           42  01-09-2017 19:49        0         0   \n",
       "\n",
       "  communication_type  total_links  no_of_internal_links  no_of_images  \\\n",
       "0         Newsletter           88                    79            13   \n",
       "1         Newsletter           88                    79            13   \n",
       "2         Newsletter           88                    79            13   \n",
       "3         Newsletter           88                    79            13   \n",
       "4         Newsletter           88                    79            13   \n",
       "\n",
       "   no_of_sections                                         email_body  \\\n",
       "0               4  September Newsletter\\r\\n \\r\\nDear AVians,\\r\\n ...   \n",
       "1               4  September Newsletter\\r\\n \\r\\nDear AVians,\\r\\n ...   \n",
       "2               4  September Newsletter\\r\\n \\r\\nDear AVians,\\r\\n ...   \n",
       "3               4  September Newsletter\\r\\n \\r\\nDear AVians,\\r\\n ...   \n",
       "4               4  September Newsletter\\r\\n \\r\\nDear AVians,\\r\\n ...   \n",
       "\n",
       "                                             subject  \\\n",
       "0  [September] Exciting days ahead with DataHack ...   \n",
       "1  [September] Exciting days ahead with DataHack ...   \n",
       "2  [September] Exciting days ahead with DataHack ...   \n",
       "3  [September] Exciting days ahead with DataHack ...   \n",
       "4  [September] Exciting days ahead with DataHack ...   \n",
       "\n",
       "                                           email_url  \n",
       "0  http://r.newsletters.analyticsvidhya.com/7v3rd...  \n",
       "1  http://r.newsletters.analyticsvidhya.com/7v3rd...  \n",
       "2  http://r.newsletters.analyticsvidhya.com/7v3rd...  \n",
       "3  http://r.newsletters.analyticsvidhya.com/7v3rd...  \n",
       "4  http://r.newsletters.analyticsvidhya.com/7v3rd...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouping variables creation\n",
      "Assigning data types for variables\n"
     ]
    }
   ],
   "source": [
    "print('Grouping variables creation')\n",
    "# ip - user_id,  Channel - campaign_id\n",
    "gp = train_df[['user_id','campaign_id']].groupby(by=['user_id'])[['campaign_id']].count().reset_index().rename(index=str, columns={'campaign_id': 'totcnt'})\n",
    "train_df = train_df.merge(gp, on=['user_id'], how='left')\n",
    "del gp\n",
    "gc.collect()\n",
    "gp = train_df[['user_id','is_open']].groupby(by=['user_id'])[['is_open']].sum().reset_index().rename(index=str, columns={'is_open': 'opncnt'})\n",
    "train_df = train_df.merge(gp, on=['user_id'], how='left')\n",
    "del gp\n",
    "gc.collect()\n",
    "gp = train_df[['user_id','is_click']].groupby(by=['user_id'])[['is_click']].sum().reset_index().rename(index=str, columns={'is_click': 'clkcnt'})\n",
    "train_df = train_df.merge(gp, on=['user_id'], how='left')\n",
    "del gp\n",
    "gc.collect()\n",
    "\n",
    "gp = train_df[['user_id','dow','campaign_id']].groupby(by=['user_id','dow'])[['campaign_id']].count().reset_index().rename(index=str, columns={'campaign_id': 'dowcnt'})\n",
    "train_df = train_df.merge(gp, on=['user_id','dow'], how='left')\n",
    "del gp\n",
    "gc.collect()\n",
    "gp = train_df[['user_id','dow','is_click']].groupby(by=['user_id','dow'])[['is_click']].sum().reset_index().rename(index=str, columns={'is_click': 'dowclk'})\n",
    "train_df = train_df.merge(gp, on=['user_id','dow'], how='left')\n",
    "del gp\n",
    "gc.collect()\n",
    "\n",
    "gp = train_df[['user_id','day','campaign_id']].groupby(by=['user_id','day'])[['campaign_id']].count().reset_index().rename(index=str, columns={'campaign_id': 'daycnt'})\n",
    "train_df = train_df.merge(gp, on=['user_id','day'], how='left')\n",
    "del gp\n",
    "gc.collect()\n",
    "gp = train_df[['user_id','day','is_click']].groupby(by=['user_id','day'])[['is_click']].sum().reset_index().rename(index=str, columns={'is_click': 'dayclk'})\n",
    "train_df = train_df.merge(gp, on=['user_id','day'], how='left')\n",
    "del gp\n",
    "gc.collect()\n",
    "\n",
    "gp = train_df[['user_id','hour','campaign_id']].groupby(by=['user_id','hour'])[['campaign_id']].count().reset_index().rename(index=str, columns={'campaign_id': 'hourcnt'})\n",
    "train_df = train_df.merge(gp, on=['user_id','hour'], how='left')\n",
    "del gp\n",
    "gc.collect()\n",
    "gp = train_df[['user_id','hour','is_click']].groupby(by=['user_id','hour'])[['is_click']].sum().reset_index().rename(index=str, columns={'is_click': 'hourclk'})\n",
    "train_df = train_df.merge(gp, on=['user_id','hour'], how='left')\n",
    "del gp\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Assigning data types for variables\")\n",
    "train_df['totcnt'] = train_df['totcnt'].fillna(0).astype('uint16')\n",
    "train_df['opncnt'] = train_df['opncnt'].fillna(0).astype('uint16')\n",
    "train_df['clkcnt'] = train_df['clkcnt'].fillna(0).astype('uint16')\n",
    "train_df['dowcnt'] = train_df['dowcnt'].fillna(0).astype('uint16')\n",
    "train_df['dowclk'] = train_df['dowclk'].fillna(0).astype('uint16')\n",
    "train_df['daycnt'] = train_df['daycnt'].fillna(0).astype('uint16')\n",
    "train_df['dayclk'] = train_df['dayclk'].fillna(0).astype('uint16')\n",
    "train_df['hourcnt'] = train_df['hourcnt'].fillna(0).astype('uint16')\n",
    "train_df['hourclk'] = train_df['hourclk'].fillna(0).astype('uint16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1023191, 26) (773858, 26)\n"
     ]
    }
   ],
   "source": [
    "test = train_df[len_train:]\n",
    "train = train_df[:len_train]\n",
    "print(train.shape,test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['campaign_id', 'communication_type', 'email_body', 'email_url', 'id',\n",
       "       'is_click', 'is_open', 'no_of_images', 'no_of_internal_links',\n",
       "       'no_of_sections', 'send_date', 'subject', 'total_links', 'user_id',\n",
       "       'hour', 'day', 'dow', 'totcnt', 'opncnt', 'clkcnt', 'dowcnt', 'dowclk',\n",
       "       'daycnt', 'dayclk', 'hourcnt', 'hourclk'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1023191, 13) (773858, 13)\n"
     ]
    }
   ],
   "source": [
    "# prep data for Base Model\n",
    "target_train = train['is_click']\n",
    "id_test = test['id']\n",
    "\n",
    "del train['campaign_id'],train['id'],train['user_id'],train['is_open'],train['is_click'],train['email_body'],train['subject'],train['email_url'],train['send_date'],train['no_of_images'],train['no_of_internal_links'],train['no_of_sections'],train['total_links']\n",
    "del test['campaign_id'],test['id'],test['user_id'],test['is_open'],test['is_click'],test['email_body'],test['subject'],test['email_url'],test['send_date'],test['no_of_images'],test['no_of_internal_links'],test['no_of_sections'],test['total_links']\n",
    "\n",
    "print(train.shape,test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1023191, 29) (773858, 27)\n"
     ]
    }
   ],
   "source": [
    "train_cats = pd.get_dummies(data=train, columns=['communication_type','dow','hour','day'], drop_first=True)\n",
    "test_cats = pd.get_dummies(data=test, columns=['communication_type','dow','hour','day'], drop_first=True)\n",
    "print (train_cats.shape,test_cats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['totcnt', 'opncnt', 'clkcnt', 'dowcnt', 'dowclk', 'daycnt', 'dayclk',\n",
       "       'hourcnt', 'hourclk', 'communication_type_Corporate',\n",
       "       'communication_type_Hackathon', 'communication_type_Newsletter',\n",
       "       'communication_type_Others', 'communication_type_Upcoming Events',\n",
       "       'communication_type_Webinar', 'dow_Mon', 'dow_Sat', 'dow_Sun',\n",
       "       'dow_Thr', 'dow_Tue', 'dow_Wed', 'hour_PM1', 'hour_PM2', 'hour_PM3',\n",
       "       'hour_PM4', 'day_LAT', 'day_MID', 'day_VLAT', 'day_VMID'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cats.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "listA = list(train_cats.columns.values)\n",
    "listB = list(test_cats.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "communication_type_Corporate\n",
      "communication_type_Others\n",
      "communication_type_Webinar\n",
      "day_LAT\n",
      "day_VLAT\n"
     ]
    }
   ],
   "source": [
    "for item in listA:\n",
    "    if item not in listB:\n",
    "        print (item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hour_AM3\n",
      "hour_AM4\n",
      "day_VEAR\n"
     ]
    }
   ],
   "source": [
    "for item in listB:\n",
    "    if item not in listA:\n",
    "        print (item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cats['communication_type_Corporate'],test_cats['communication_type_Others'],test_cats['communication_type_Webinar'],test_cats['day_LAT'],test_cats['day_VLAT']=0,0,0,0,0\n",
    "train_cats['hour_AM3'],train_cats['hour_AM4'],train_cats['hour_AM4'] =0,0,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['totcnt', 'opncnt', 'clkcnt', 'dowcnt', 'dowclk', 'daycnt', 'dayclk',\n",
       "       'hourcnt', 'hourclk', 'communication_type_Corporate',\n",
       "       'communication_type_Hackathon', 'communication_type_Newsletter',\n",
       "       'communication_type_Others', 'communication_type_Upcoming Events',\n",
       "       'communication_type_Webinar', 'dow_Mon', 'dow_Sat', 'dow_Sun',\n",
       "       'dow_Thr', 'dow_Tue', 'dow_Wed', 'hour_PM1', 'hour_PM2', 'hour_PM3',\n",
       "       'hour_PM4', 'day_LAT', 'day_MID', 'day_VLAT', 'day_VMID', 'hour_AM3',\n",
       "       'hour_AM4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cats.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cats = train_cats[['totcnt', 'opncnt', 'clkcnt', 'dowcnt', 'dowclk', 'daycnt', 'dayclk','hourcnt', 'hourclk',\n",
    "                        'communication_type_Corporate','communication_type_Hackathon','communication_type_Newsletter',\n",
    "                        'communication_type_Others','communication_type_Upcoming Events','communication_type_Webinar',\n",
    "                        'dow_Mon', 'dow_Sat', 'dow_Sun','dow_Thr', 'dow_Tue', 'dow_Wed', 'hour_PM1', 'hour_PM2',\n",
    "                        'hour_PM3','hour_PM4', 'day_LAT', 'day_MID', 'day_VLAT', 'day_VMID', 'hour_AM3','hour_AM4']]\n",
    "\n",
    "test_cats = test_cats[['totcnt', 'opncnt', 'clkcnt', 'dowcnt', 'dowclk', 'daycnt', 'dayclk','hourcnt', 'hourclk',\n",
    "                      'communication_type_Corporate','communication_type_Hackathon','communication_type_Newsletter',\n",
    "                      'communication_type_Others','communication_type_Upcoming Events','communication_type_Webinar',\n",
    "                      'dow_Mon', 'dow_Sat', 'dow_Sun','dow_Thr', 'dow_Tue', 'dow_Wed', 'hour_PM1', 'hour_PM2',\n",
    "                      'hour_PM3','hour_PM4', 'day_LAT', 'day_MID', 'day_VLAT', 'day_VMID', 'hour_AM3','hour_AM4']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = np.array(train_cats)\n",
    "testdf = np.array(test_cats)\n",
    "\n",
    "xgb_preds = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "kf = KFold(n_splits = K, random_state = 42, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-21-a6849180cd34>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-21-a6849180cd34>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    xgb_params = {'eta': 0.02, 'objective': 'binary:logistic', max_depth= 6, subsample = 1, colsample_bytree = 1,\u001b[0m\n\u001b[0m                                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "for train_index, test_index in kf.split(traindf):\n",
    "    train_X, valid_X = traindf[train_index], traindf[test_index]\n",
    "    train_y, valid_y = target_train[train_index], target_train[test_index]\n",
    "\n",
    "    # params configuration also from the1owl's kernel\n",
    "    # https://www.kaggle.com/the1owl/forza-baseline\n",
    "    xgb_params = {'eta': 0.02, 'objective': 'binary:logistic', max_depth= 6, subsample = 1, colsample_bytree = 1,\n",
    "                  min_chil_weight=1, 'eval_metric': 'auc', 'seed': 42, 'silent': True}\n",
    "\n",
    "    d_train = xgb.DMatrix(train_X, train_y)\n",
    "    d_valid = xgb.DMatrix(valid_X, valid_y)\n",
    "    d_test = xgb.DMatrix(testdf)\n",
    "    \n",
    "    watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "    model = xgb.train(xgb_params, d_train, 5000,  watchlist, \n",
    "                      maximize=True, verbose_eval=50, early_stopping_rounds=50)\n",
    "                        \n",
    "    xgb_pred = model.predict(d_test)\n",
    "    xgb_preds.append(list(xgb_pred))\n",
    "\n",
    "end = time()\n",
    "print ('Time taken is:', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=[]\n",
    "for i in range(len(xgb_preds[0])):\n",
    "    sum=0\n",
    "    for j in range(K):\n",
    "        sum+=xgb_preds[j][i]\n",
    "    preds.append(sum / K)\n",
    "\n",
    "out = pd.DataFrame({'id': id_test, 'is_click': preds})\n",
    "out.to_csv(\"pred3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
