{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "#import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from time import time\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the train data is  (920871, 14)  Test data is  (773858, 12)  Valid data is (102320, 14)\n"
     ]
    }
   ],
   "source": [
    "path = '/Users/804357/Desktop/MyFiles/Learn/LOM/Data/'\n",
    "#path = '/Users/Vishy/Files/AVDatahack/LOM/Data/' \n",
    "train = pd.read_csv(path+'train.csv')\n",
    "test = pd.read_csv(path+'test.csv')\n",
    "camp = pd.read_csv(path+'campaign_data.csv')\n",
    "\n",
    "train_df = pd.merge(train, camp, on='campaign_id')\n",
    "test_df = pd.merge(test, camp, on='campaign_id')\n",
    "train_df, dev_df = train_test_split(train_df, random_state=42, test_size=0.10)\n",
    "\n",
    "print('Shape of the train data is ',train_df.shape,' Test data is ',test_df.shape,' Valid data is',dev_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hackathon          13\n",
       "Corporate          12\n",
       "Newsletter          9\n",
       "Conference          8\n",
       "Upcoming Events     7\n",
       "Others              2\n",
       "Webinar             1\n",
       "Name: communication_type, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camp.communication_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_trains = train_df.shape[0]\n",
    "n_devs = dev_df.shape[0]\n",
    "n_tests = test_df.shape[0]\n",
    "\n",
    "full_df = pd.concat([train_df,dev_df,test_df])\n",
    "del train_df,dev_df,test_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New date variable creations\n"
     ]
    }
   ],
   "source": [
    "print('New date variable creations')\n",
    "#train\n",
    "full_df['hour'] = pd.to_datetime(full_df.send_date).dt.hour.astype('uint8')\n",
    "full_df['day'] = pd.to_datetime(full_df.send_date).dt.day.astype('uint8')\n",
    "full_df['dow'] = pd.to_datetime(full_df.send_date).dt.dayofweek.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['campaign_id', 'communication_type', 'email_body', 'email_url',\n",
       "       'id', 'is_click', 'is_open', 'no_of_images', 'no_of_internal_links',\n",
       "       'no_of_sections', 'send_date', 'subject', 'total_links', 'user_id',\n",
       "       'hour', 'day', 'dow'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renaming of the new date variables created\n"
     ]
    }
   ],
   "source": [
    "print('Renaming of the new date variables created')\n",
    "full_df['dow'] = full_df['dow'].map({0:'MON', 1:'TUE', 2:'WED', 3:'THR',4: 'FRI', 5: 'SAT', 6: 'SUN'} ).astype(str)\n",
    "full_df['hour'] = full_df['hour'].map({0:'AM1', 1:'AM1', 2:'AM1', 3:'AM2', 4:'AM2', 5:'AM2', 6:'AM3', 7:'AM3', 8:'AM3',\n",
    "                                         9:'AM4', 10:'AM4', 11:'AM4', 12:'PM1', 13:'PM1', 14:'PM1', 15:'PM2', 16:'PM2',\n",
    "                                         17:'PM2', 18:'PM3', 19:'PM3', 20:'PM3', 21:'PM4', 22:'PM4', 23:'PM4'}).astype(str)\n",
    "full_df['day'] = full_df['day'].map({1:'VEAR', 2:'VEAR', 3:'VEAR', 4:'VEAR', 5:'VEAR', 6:'EAR', 7:'EAR', 8:'EAR',\n",
    "                                       9:'EAR', 10:'EAR', 11:'MID', 12:'MID', 13:'MID', 14:'MID', 15:'MID', 16:'VMID',\n",
    "                                       17:'VMID', 18:'VMID', 19:'VMID', 20:'VMID', 21:'LAT', 22:'LAT', 23:'LAT', \n",
    "                                       24:'LAT', 25:'LAT', 26:'VLAT', 27:'VLAT', 28:'VLAT', 29:'VLAT', 30:'VLAT',\n",
    "                                       31:'VLAT'}).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(920871, 17) (773858, 17) (102320, 17)\n"
     ]
    }
   ],
   "source": [
    "train_df = full_df[:n_trains]\n",
    "dev_df = full_df[n_trains:n_trains+n_devs]\n",
    "test_df = full_df[n_trains+n_devs:]\n",
    "print(train_df.shape,test_df.shape,dev_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# del gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouping variables creation for train_data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "118"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Grouping variables creation for train_data')\n",
    "# ip - user_id,  Channel - campaign_id\n",
    "\n",
    "# Campaigns per communication\n",
    "gp = train_df[['communication_type','campaign_id']].groupby(by=['communication_type'])[['campaign_id']].count().reset_index().rename(index=str, columns={'campaign_id': 'totcom'})\n",
    "train_df = train_df.merge(gp, on=['communication_type'], how='left')\n",
    "dev_df = dev_df.merge(gp, on=['communication_type'], how='left')\n",
    "test_df = test_df.merge(gp, on=['communication_type'], how='left')\n",
    "del gp\n",
    "gc.collect()\n",
    "# open count per communication\n",
    "gp = train_df[['communication_type','is_open']].groupby(by=['communication_type'])[['is_open']].sum().reset_index().rename(index=str, columns={'is_open': 'opncom'})\n",
    "train_df = train_df.merge(gp, on=['communication_type'], how='left')\n",
    "dev_df = dev_df.merge(gp, on=['communication_type'], how='left')\n",
    "test_df = test_df.merge(gp, on=['communication_type'], how='left')\n",
    "del gp\n",
    "gc.collect()\n",
    "# Click count per communication\n",
    "gp = train_df[['communication_type','is_click']].groupby(by=['communication_type'])[['is_click']].sum().reset_index().rename(index=str, columns={'is_click': 'clkcom'})\n",
    "train_df = train_df.merge(gp, on=['communication_type'], how='left')\n",
    "dev_df = dev_df.merge(gp, on=['communication_type'], how='left')\n",
    "test_df = test_df.merge(gp, on=['communication_type'], how='left')\n",
    "del gp\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "gp = train_df[['communication_type','dow','campaign_id']].groupby(by=['communication_type','dow'])[['campaign_id']].count().reset_index().rename(index=str, columns={'campaign_id': 'totdow'})\n",
    "train_df = train_df.merge(gp, on=['communication_type','dow'], how='left')\n",
    "dev_df = dev_df.merge(gp, on=['communication_type','dow'], how='left')\n",
    "test_df = test_df.merge(gp, on=['communication_type','dow'], how='left')\n",
    "del gp\n",
    "gc.collect()\n",
    "gp = train_df[['communication_type','dow','is_open']].groupby(by=['communication_type','dow'])[['is_open']].sum().reset_index().rename(index=str, columns={'is_open': 'opndow'})\n",
    "train_df = train_df.merge(gp, on=['communication_type','dow'], how='left')\n",
    "dev_df = dev_df.merge(gp, on=['communication_type','dow'], how='left')\n",
    "test_df = test_df.merge(gp, on=['communication_type','dow'], how='left')\n",
    "del gp\n",
    "gc.collect()\n",
    "gp = train_df[['communication_type','dow','is_click']].groupby(by=['communication_type','dow'])[['is_click']].sum().reset_index().rename(index=str, columns={'is_click': 'clkdow'})\n",
    "train_df = train_df.merge(gp, on=['communication_type','dow'], how='left')\n",
    "dev_df = dev_df.merge(gp, on=['communication_type','dow'], how='left')\n",
    "test_df = test_df.merge(gp, on=['communication_type','dow'], how='left')\n",
    "del gp\n",
    "gc.collect()\n",
    "\n",
    "gp = train_df[['communication_type','day','campaign_id']].groupby(by=['communication_type','day'])[['campaign_id']].count().reset_index().rename(index=str, columns={'campaign_id': 'totday'})\n",
    "train_df = train_df.merge(gp, on=['communication_type','day'], how='left')\n",
    "dev_df = dev_df.merge(gp, on=['communication_type','day'], how='left')\n",
    "test_df = test_df.merge(gp, on=['communication_type','day'], how='left')\n",
    "del gp\n",
    "gc.collect()\n",
    "gp = train_df[['communication_type','day','is_open']].groupby(by=['communication_type','day'])[['is_open']].sum().reset_index().rename(index=str, columns={'is_open': 'opnday'})\n",
    "train_df = train_df.merge(gp, on=['communication_type','day'], how='left')\n",
    "dev_df = dev_df.merge(gp, on=['communication_type','day'], how='left')\n",
    "test_df = test_df.merge(gp, on=['communication_type','day'], how='left')\n",
    "del gp\n",
    "gc.collect()\n",
    "gp = train_df[['communication_type','day','is_click']].groupby(by=['communication_type','day'])[['is_click']].sum().reset_index().rename(index=str, columns={'is_click': 'clkday'})\n",
    "train_df = train_df.merge(gp, on=['communication_type','day'], how='left')\n",
    "dev_df = dev_df.merge(gp, on=['communication_type','day'], how='left')\n",
    "test_df = test_df.merge(gp, on=['communication_type','day'], how='left')\n",
    "del gp\n",
    "gc.collect()\n",
    "\n",
    "gp = train_df[['communication_type','hour','campaign_id']].groupby(by=['communication_type','hour'])[['campaign_id']].count().reset_index().rename(index=str, columns={'campaign_id': 'tothour'})\n",
    "train_df = train_df.merge(gp, on=['communication_type','hour'], how='left')\n",
    "dev_df = dev_df.merge(gp, on=['communication_type','hour'], how='left')\n",
    "test_df = test_df.merge(gp, on=['communication_type','hour'], how='left')\n",
    "del gp\n",
    "gc.collect()\n",
    "\n",
    "gp = train_df[['communication_type','hour','is_open']].groupby(by=['communication_type','hour'])[['is_open']].sum().reset_index().rename(index=str, columns={'is_open': 'opnhour'})\n",
    "train_df = train_df.merge(gp, on=['communication_type','hour'], how='left')\n",
    "dev_df = dev_df.merge(gp, on=['communication_type','hour'], how='left')\n",
    "test_df = test_df.merge(gp, on=['communication_type','hour'], how='left')\n",
    "del gp\n",
    "gc.collect()\n",
    "\n",
    "gp = train_df[['communication_type','hour','is_click']].groupby(by=['communication_type','hour'])[['is_click']].sum().reset_index().rename(index=str, columns={'is_click': 'clkhour'})\n",
    "train_df = train_df.merge(gp, on=['communication_type','hour'], how='left')\n",
    "dev_df = dev_df.merge(gp, on=['communication_type','hour'], how='left')\n",
    "test_df = test_df.merge(gp, on=['communication_type','hour'], how='left')\n",
    "del gp\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigning data types for Training variables\n"
     ]
    }
   ],
   "source": [
    "print(\"Assigning data types for Training variables\")\n",
    "train_df['totcom'] = train_df['totcom'].fillna(0).astype('uint16')\n",
    "train_df['opncom'] = train_df['opncom'].fillna(0).astype('uint16')\n",
    "train_df['clkcom'] = train_df['clkcom'].fillna(0).astype('uint16')\n",
    "train_df['opncomrate'] = ((train_df['opncom']/train_df['totcom']).replace(np.inf, 0))\n",
    "train_df['clkcomrate'] = ((train_df['clkcom']/train_df['totcom']).replace(np.inf, 0))\n",
    "\n",
    "train_df['totdow'] = train_df['totdow'].fillna(0).astype('uint16')\n",
    "train_df['opndow'] = train_df['opndow'].fillna(0).astype('uint16')\n",
    "train_df['clkdow'] = train_df['clkdow'].fillna(0).astype('uint16')\n",
    "train_df['opndowrate'] = ((train_df['opndow']/train_df['totdow']).replace(np.inf, 0))\n",
    "train_df['clkdowrate'] = ((train_df['clkdow']/train_df['totdow']).replace(np.inf, 0))\n",
    "\n",
    "train_df['totday'] = train_df['totday'].fillna(0).astype('uint16')\n",
    "train_df['opnday'] = train_df['opnday'].fillna(0).astype('uint16')\n",
    "train_df['clkday'] = train_df['clkday'].fillna(0).astype('uint16')\n",
    "train_df['opndayrate'] = ((train_df['opnday']/train_df['totday']).replace(np.inf, 0))\n",
    "train_df['clkdayrate'] = ((train_df['clkday']/train_df['totday']).replace(np.inf, 0))\n",
    "\n",
    "train_df['tothour'] = train_df['tothour'].fillna(0).astype('uint16')\n",
    "train_df['opnhour'] = train_df['opnhour'].fillna(0).astype('uint16')\n",
    "train_df['clkhour'] = train_df['clkhour'].fillna(0).astype('uint16')\n",
    "train_df['opnhourrate'] = ((train_df['opnhour']/train_df['tothour']).replace(np.inf, 0))\n",
    "train_df['clkhourrate'] = ((train_df['clkhour']/train_df['tothour']).replace(np.inf, 0))\n",
    "\n",
    "del train_df['totcom'],train_df['opncom'],train_df['clkcom'],train_df['totdow'],train_df['opndow'],train_df['clkdow']\n",
    "del train_df['totday'],train_df['opnday'],train_df['clkday'],train_df['tothour'],train_df['opnhour'],train_df['clkhour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dev_df['totcom'] = dev_df['totcom'].fillna(0).astype('uint16')\n",
    "dev_df['opncom'] = dev_df['opncom'].fillna(0).astype('uint16')\n",
    "dev_df['clkcom'] = dev_df['clkcom'].fillna(0).astype('uint16')\n",
    "dev_df['opncomrate'] = ((dev_df['opncom']/dev_df['totcom']).replace(np.inf, 0))\n",
    "dev_df['clkcomrate'] = ((dev_df['clkcom']/dev_df['totcom']).replace(np.inf, 0))\n",
    "\n",
    "dev_df['totdow'] = dev_df['totdow'].fillna(0).astype('uint16')\n",
    "dev_df['opndow'] = dev_df['opndow'].fillna(0).astype('uint16')\n",
    "dev_df['clkdow'] = dev_df['clkdow'].fillna(0).astype('uint16')\n",
    "dev_df['opndowrate'] = ((dev_df['opndow']/dev_df['totdow']).replace(np.inf, 0))\n",
    "dev_df['clkdowrate'] = ((dev_df['clkdow']/dev_df['totdow']).replace(np.inf, 0))\n",
    "\n",
    "dev_df['totday'] = dev_df['totday'].fillna(0).astype('uint16')\n",
    "dev_df['opnday'] = dev_df['opnday'].fillna(0).astype('uint16')\n",
    "dev_df['clkday'] = dev_df['clkday'].fillna(0).astype('uint16')\n",
    "dev_df['opndayrate'] = ((dev_df['opnday']/dev_df['totday']).replace(np.inf, 0))\n",
    "dev_df['clkdayrate'] = ((dev_df['clkday']/dev_df['totday']).replace(np.inf, 0))\n",
    "\n",
    "dev_df['tothour'] = dev_df['tothour'].fillna(0).astype('uint16')\n",
    "dev_df['opnhour'] = dev_df['opnhour'].fillna(0).astype('uint16')\n",
    "dev_df['clkhour'] = dev_df['clkhour'].fillna(0).astype('uint16')\n",
    "dev_df['opnhourrate'] = ((dev_df['opnhour']/dev_df['tothour']).replace(np.inf, 0))\n",
    "dev_df['clkhourrate'] = ((dev_df['clkhour']/dev_df['tothour']).replace(np.inf, 0))\n",
    "\n",
    "del dev_df['totcom'],dev_df['opncom'],dev_df['clkcom'],dev_df['totdow'],dev_df['opndow'],dev_df['clkdow']\n",
    "del dev_df['totday'],dev_df['opnday'],dev_df['clkday'],dev_df['tothour'],dev_df['opnhour'],dev_df['clkhour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df['totcom'] = test_df['totcom'].fillna(0).astype('uint16')\n",
    "test_df['opncom'] = test_df['opncom'].fillna(0).astype('uint16')\n",
    "test_df['clkcom'] = test_df['clkcom'].fillna(0).astype('uint16')\n",
    "test_df['opncomrate'] = ((test_df['opncom']/test_df['totcom']).replace(np.inf, 0))\n",
    "test_df['clkcomrate'] = ((test_df['clkcom']/test_df['totcom']).replace(np.inf, 0))\n",
    "\n",
    "test_df['totdow'] = test_df['totdow'].fillna(0).astype('uint16')\n",
    "test_df['opndow'] = test_df['opndow'].fillna(0).astype('uint16')\n",
    "test_df['clkdow'] = test_df['clkdow'].fillna(0).astype('uint16')\n",
    "test_df['opndowrate'] = ((test_df['opndow']/test_df['totdow']).replace(np.inf, 0))\n",
    "test_df['clkdowrate'] = ((test_df['clkdow']/test_df['totdow']).replace(np.inf, 0))\n",
    "\n",
    "test_df['totday'] = test_df['totday'].fillna(0).astype('uint16')\n",
    "test_df['opnday'] = test_df['opnday'].fillna(0).astype('uint16')\n",
    "test_df['clkday'] = test_df['clkday'].fillna(0).astype('uint16')\n",
    "test_df['opndayrate'] = ((test_df['opnday']/test_df['totday']).replace(np.inf, 0))\n",
    "test_df['clkdayrate'] = ((test_df['clkday']/test_df['totday']).replace(np.inf, 0))\n",
    "\n",
    "test_df['tothour'] = test_df['tothour'].fillna(0).astype('uint16')\n",
    "test_df['opnhour'] = test_df['opnhour'].fillna(0).astype('uint16')\n",
    "test_df['clkhour'] = test_df['clkhour'].fillna(0).astype('uint16')\n",
    "test_df['opnhourrate'] = ((test_df['opnhour']/test_df['tothour']).replace(np.inf, 0))\n",
    "test_df['clkhourrate'] = ((test_df['clkhour']/test_df['tothour']).replace(np.inf, 0))\n",
    "\n",
    "del test_df['totcom'],test_df['opncom'],test_df['clkcom'],test_df['totdow'],test_df['opndow'],test_df['clkdow']\n",
    "del test_df['totday'],test_df['opnday'],test_df['clkday'],test_df['tothour'],test_df['opnhour'],test_df['clkhour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['campaign_id', 'communication_type', 'email_body', 'email_url', 'id',\n",
       "       'is_click', 'is_open', 'no_of_images', 'no_of_internal_links',\n",
       "       'no_of_sections', 'send_date', 'subject', 'total_links', 'user_id',\n",
       "       'hour', 'day', 'dow', 'opncomrate', 'clkcomrate', 'opndowrate',\n",
       "       'clkdowrate', 'opndayrate', 'clkdayrate', 'opnhourrate', 'clkhourrate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['campaign_id', 'communication_type', 'email_body', 'email_url', 'id',\n",
       "       'is_click', 'is_open', 'no_of_images', 'no_of_internal_links',\n",
       "       'no_of_sections', 'send_date', 'subject', 'total_links', 'user_id',\n",
       "       'hour', 'day', 'dow', 'opncomrate', 'clkcomrate', 'opndowrate',\n",
       "       'clkdowrate', 'opndayrate', 'clkdayrate', 'opnhourrate', 'clkhourrate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train = train_df[['is_click', 'is_open']]\n",
    "Y_Dev = dev_df[[ 'is_click', 'is_open']]\n",
    "del train_df['is_click'],train_df['is_open'],dev_df['is_click'],dev_df['is_open'],test_df['is_click'],test_df['is_open']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(920871, 16) (102320, 16) (773858, 16)\n"
     ]
    }
   ],
   "source": [
    "# Delete unnecessary variables\n",
    "id_test = test_df['id']\n",
    "del train_df['campaign_id'],train_df['email_body'],train_df['email_url'],train_df['id'],train_df['send_date'],train_df['subject'],train_df['user_id']\n",
    "del dev_df['campaign_id'],dev_df['email_body'],dev_df['email_url'],dev_df['id'],dev_df['send_date'],dev_df['subject'],dev_df['user_id']\n",
    "del test_df['campaign_id'],test_df['email_body'],test_df['email_url'],test_df['id'],test_df['send_date'],test_df['subject'],test_df['user_id']\n",
    "print(train_df.shape,dev_df.shape,test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>communication_type</th>\n",
       "      <th>no_of_images</th>\n",
       "      <th>no_of_internal_links</th>\n",
       "      <th>no_of_sections</th>\n",
       "      <th>total_links</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>dow</th>\n",
       "      <th>opncomrate</th>\n",
       "      <th>clkcomrate</th>\n",
       "      <th>opndowrate</th>\n",
       "      <th>clkdowrate</th>\n",
       "      <th>opndayrate</th>\n",
       "      <th>clkdayrate</th>\n",
       "      <th>opnhourrate</th>\n",
       "      <th>clkhourrate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Conference</td>\n",
       "      <td>13</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>104</td>\n",
       "      <td>PM4</td>\n",
       "      <td>MID</td>\n",
       "      <td>SUN</td>\n",
       "      <td>0.720094</td>\n",
       "      <td>0.077426</td>\n",
       "      <td>0.243340</td>\n",
       "      <td>0.065421</td>\n",
       "      <td>0.243340</td>\n",
       "      <td>0.065421</td>\n",
       "      <td>0.243340</td>\n",
       "      <td>0.065421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Others</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>PM2</td>\n",
       "      <td>LAT</td>\n",
       "      <td>MON</td>\n",
       "      <td>0.201903</td>\n",
       "      <td>0.014378</td>\n",
       "      <td>0.226826</td>\n",
       "      <td>0.011877</td>\n",
       "      <td>0.226826</td>\n",
       "      <td>0.011877</td>\n",
       "      <td>0.223211</td>\n",
       "      <td>0.015696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Conference</td>\n",
       "      <td>16</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "      <td>119</td>\n",
       "      <td>PM2</td>\n",
       "      <td>VLAT</td>\n",
       "      <td>THR</td>\n",
       "      <td>0.720094</td>\n",
       "      <td>0.077426</td>\n",
       "      <td>0.500594</td>\n",
       "      <td>0.122309</td>\n",
       "      <td>0.500594</td>\n",
       "      <td>0.122309</td>\n",
       "      <td>0.651360</td>\n",
       "      <td>0.063647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Upcoming Events</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>PM1</td>\n",
       "      <td>EAR</td>\n",
       "      <td>SUN</td>\n",
       "      <td>3.965905</td>\n",
       "      <td>0.555484</td>\n",
       "      <td>0.141751</td>\n",
       "      <td>0.012699</td>\n",
       "      <td>3.965905</td>\n",
       "      <td>0.555484</td>\n",
       "      <td>0.321901</td>\n",
       "      <td>0.039611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newsletter</td>\n",
       "      <td>13</td>\n",
       "      <td>79</td>\n",
       "      <td>4</td>\n",
       "      <td>88</td>\n",
       "      <td>PM3</td>\n",
       "      <td>EAR</td>\n",
       "      <td>MON</td>\n",
       "      <td>2.657940</td>\n",
       "      <td>0.398875</td>\n",
       "      <td>0.505684</td>\n",
       "      <td>0.121652</td>\n",
       "      <td>0.262997</td>\n",
       "      <td>0.062272</td>\n",
       "      <td>1.064677</td>\n",
       "      <td>0.121755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  communication_type  no_of_images  no_of_internal_links  no_of_sections  \\\n",
       "0         Conference            13                   100               1   \n",
       "1             Others             1                     3               1   \n",
       "2         Conference            16                   117               1   \n",
       "3    Upcoming Events             7                    14               1   \n",
       "4         Newsletter            13                    79               4   \n",
       "\n",
       "   total_links hour   day  dow  opncomrate  clkcomrate  opndowrate  \\\n",
       "0          104  PM4   MID  SUN    0.720094    0.077426    0.243340   \n",
       "1            7  PM2   LAT  MON    0.201903    0.014378    0.226826   \n",
       "2          119  PM2  VLAT  THR    0.720094    0.077426    0.500594   \n",
       "3           18  PM1   EAR  SUN    3.965905    0.555484    0.141751   \n",
       "4           88  PM3   EAR  MON    2.657940    0.398875    0.505684   \n",
       "\n",
       "   clkdowrate  opndayrate  clkdayrate  opnhourrate  clkhourrate  \n",
       "0    0.065421    0.243340    0.065421     0.243340     0.065421  \n",
       "1    0.011877    0.226826    0.011877     0.223211     0.015696  \n",
       "2    0.122309    0.500594    0.122309     0.651360     0.063647  \n",
       "3    0.012699    3.965905    0.555484     0.321901     0.039611  \n",
       "4    0.121652    0.262997    0.062272     1.064677     0.121755  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(920871, 32) (773858, 30) (102320, 32)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.get_dummies(data=train_df, columns=['communication_type','dow','hour','day'], drop_first=True)\n",
    "dev_df = pd.get_dummies(data=dev_df, columns=['communication_type','dow','hour','day'], drop_first=True)\n",
    "test_df = pd.get_dummies(data=test_df, columns=['communication_type','dow','hour','day'], drop_first=True)\n",
    "print (train_df.shape,test_df.shape,dev_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['no_of_images', 'no_of_internal_links', 'no_of_sections', 'total_links',\n",
       "       'opncomrate', 'clkcomrate', 'opndowrate', 'clkdowrate', 'opndayrate',\n",
       "       'clkdayrate', 'opnhourrate', 'clkhourrate',\n",
       "       'communication_type_Corporate', 'communication_type_Hackathon',\n",
       "       'communication_type_Newsletter', 'communication_type_Others',\n",
       "       'communication_type_Upcoming Events', 'communication_type_Webinar',\n",
       "       'dow_MON', 'dow_SAT', 'dow_SUN', 'dow_THR', 'dow_TUE', 'dow_WED',\n",
       "       'hour_PM1', 'hour_PM2', 'hour_PM3', 'hour_PM4', 'day_LAT', 'day_MID',\n",
       "       'day_VLAT', 'day_VMID'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['no_of_images', 'no_of_internal_links', 'no_of_sections', 'total_links',\n",
       "       'opncomrate', 'clkcomrate', 'opndowrate', 'clkdowrate', 'opndayrate',\n",
       "       'clkdayrate', 'opnhourrate', 'clkhourrate',\n",
       "       'communication_type_Corporate', 'communication_type_Hackathon',\n",
       "       'communication_type_Newsletter', 'communication_type_Others',\n",
       "       'communication_type_Upcoming Events', 'communication_type_Webinar',\n",
       "       'dow_MON', 'dow_SAT', 'dow_SUN', 'dow_THR', 'dow_TUE', 'dow_WED',\n",
       "       'hour_PM1', 'hour_PM2', 'hour_PM3', 'hour_PM4', 'day_LAT', 'day_MID',\n",
       "       'day_VLAT', 'day_VMID'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['no_of_images', 'no_of_internal_links', 'no_of_sections', 'total_links',\n",
       "       'opncomrate', 'clkcomrate', 'opndowrate', 'clkdowrate', 'opndayrate',\n",
       "       'clkdayrate', 'opnhourrate', 'clkhourrate',\n",
       "       'communication_type_Hackathon', 'communication_type_Newsletter',\n",
       "       'communication_type_Upcoming Events', 'dow_MON', 'dow_SAT', 'dow_SUN',\n",
       "       'dow_THR', 'dow_TUE', 'dow_WED', 'hour_AM3', 'hour_AM4', 'hour_PM1',\n",
       "       'hour_PM2', 'hour_PM3', 'hour_PM4', 'day_MID', 'day_VEAR', 'day_VMID'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(920871, 36) (773858, 36) (102320, 36)\n"
     ]
    }
   ],
   "source": [
    "test_df['communication_type_Corporate'],test_df['communication_type_Others'],test_df['communication_type_Webinar'],test_df['day_VMID'],test_df['day_LAT'],test_df['day_VLAT'],test_df['hour_AM2']=0,0,0,0,0,0,0\n",
    "train_df['hour_AM2'],train_df['hour_AM3'],train_df['hour_AM4'],train_df['day_VEAR'] = 0,0,0,0\n",
    "dev_df['hour_AM2'],dev_df['hour_AM3'],dev_df['hour_AM4'],dev_df['day_VEAR'] = 0,0,0,0\n",
    "print(train_df.shape,test_df.shape,dev_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['no_of_images', 'no_of_internal_links', 'no_of_sections', 'total_links',\n",
       "       'opncomrate', 'clkcomrate', 'opndowrate', 'clkdowrate', 'opndayrate',\n",
       "       'clkdayrate', 'opnhourrate', 'clkhourrate',\n",
       "       'communication_type_Corporate', 'communication_type_Hackathon',\n",
       "       'communication_type_Newsletter', 'communication_type_Others',\n",
       "       'communication_type_Upcoming Events', 'communication_type_Webinar',\n",
       "       'dow_MON', 'dow_SAT', 'dow_SUN', 'dow_THR', 'dow_TUE', 'dow_WED',\n",
       "       'hour_PM1', 'hour_PM2', 'hour_PM3', 'hour_PM4', 'day_LAT', 'day_MID',\n",
       "       'day_VLAT', 'day_VMID', 'hour_AM2', 'hour_AM3', 'hour_AM4', 'day_VEAR'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df=train_df[['no_of_images', 'no_of_internal_links', 'no_of_sections', 'total_links',\n",
    "       'opncomrate', 'clkcomrate', 'opndowrate', 'clkdowrate', 'opndayrate',\n",
    "       'clkdayrate', 'opnhourrate', 'clkhourrate',\n",
    "       'communication_type_Corporate', 'communication_type_Hackathon',\n",
    "       'communication_type_Newsletter', 'communication_type_Others',\n",
    "       'communication_type_Upcoming Events', 'communication_type_Webinar',\n",
    "       'dow_MON', 'dow_SAT', 'dow_SUN', 'dow_THR', 'dow_TUE', 'dow_WED',\n",
    "       'hour_PM1', 'hour_PM2', 'hour_PM3', 'hour_PM4', 'day_LAT', 'day_MID',\n",
    "       'day_VLAT', 'day_VMID', 'hour_AM2', 'hour_AM3', 'hour_AM4', 'day_VEAR']]\n",
    "dev_df=dev_df[['no_of_images', 'no_of_internal_links', 'no_of_sections', 'total_links',\n",
    "       'opncomrate', 'clkcomrate', 'opndowrate', 'clkdowrate', 'opndayrate',\n",
    "       'clkdayrate', 'opnhourrate', 'clkhourrate',\n",
    "       'communication_type_Corporate', 'communication_type_Hackathon',\n",
    "       'communication_type_Newsletter', 'communication_type_Others',\n",
    "       'communication_type_Upcoming Events', 'communication_type_Webinar',\n",
    "       'dow_MON', 'dow_SAT', 'dow_SUN', 'dow_THR', 'dow_TUE', 'dow_WED',\n",
    "       'hour_PM1', 'hour_PM2', 'hour_PM3', 'hour_PM4', 'day_LAT', 'day_MID',\n",
    "       'day_VLAT', 'day_VMID', 'hour_AM2', 'hour_AM3', 'hour_AM4', 'day_VEAR']]\n",
    "test_df=test_df[['no_of_images', 'no_of_internal_links', 'no_of_sections', 'total_links',\n",
    "       'opncomrate', 'clkcomrate', 'opndowrate', 'clkdowrate', 'opndayrate',\n",
    "       'clkdayrate', 'opnhourrate', 'clkhourrate',\n",
    "       'communication_type_Corporate', 'communication_type_Hackathon',\n",
    "       'communication_type_Newsletter', 'communication_type_Others',\n",
    "       'communication_type_Upcoming Events', 'communication_type_Webinar',\n",
    "       'dow_MON', 'dow_SAT', 'dow_SUN', 'dow_THR', 'dow_TUE', 'dow_WED',\n",
    "       'hour_PM1', 'hour_PM2', 'hour_PM3', 'hour_PM4', 'day_LAT', 'day_MID',\n",
    "       'day_VLAT', 'day_VMID', 'hour_AM2', 'hour_AM3', 'hour_AM4', 'day_VEAR']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'learning_rate': 0.002,'application': 'binay','max_depth': 8,'num_leaves': 60,'metric': 'AUC',\n",
    "          'objective' : 'binary', 'data_random_seed': 1, 'bagging_fraction': 0.8,'nthread': 4,'scale_pos_weight':90}\n",
    " \n",
    "params2 = {'learning_rate': 0.006,'application': 'binary','max_depth': 16,'num_leaves': 130,'metric': 'AUC',\n",
    "           'objective' : 'binary', 'data_random_seed': 2,'bagging_fraction': 1,'nthread': 4,'scale_pos_weight':90} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.591432\tvalid_1's auc: 0.593349\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's auc: 0.59066\tvalid_1's auc: 0.595612\n"
     ]
    }
   ],
   "source": [
    "# Light GBM \n",
    "y_train = Y_train['is_click'].values\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(train_df,y_train,test_size = 0.2,random_state = 42)\n",
    "d_train = lgb.Dataset(train_X, label=train_y) \n",
    "d_valid = lgb.Dataset(valid_X, label=valid_y) \n",
    "watchlist = [d_train, d_valid] \n",
    "\n",
    "model3 = lgb.train(params, train_set=d_train, num_boost_round=5000, valid_sets=watchlist,\n",
    "                   early_stopping_rounds=100, verbose_eval=100) \n",
    "preds3 = model3.predict(dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.591433\tvalid_1's auc: 0.593402\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.591433\tvalid_1's auc: 0.593402\n"
     ]
    }
   ],
   "source": [
    "train_X2, valid_X2, train_y2, valid_y2 = train_test_split(train_df, y_train, test_size = 0.2, random_state = 42)  \n",
    "d_train2 = lgb.Dataset(train_X2, label=train_y2)\n",
    "d_valid2 = lgb.Dataset(valid_X2, label=valid_y2)\n",
    "watchlist2 = [d_train2, d_valid2]\n",
    "\n",
    "model4 = lgb.train(params2, train_set=d_train2, num_boost_round=6000, valid_sets=watchlist2, \n",
    "                   early_stopping_rounds=100, verbose_eval=100)  \n",
    "preds4 = model4.predict(dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC score using LGB1 is 0.591842155248\n",
      "ROC-AUC score using LGB2 is 0.591608109419\n"
     ]
    }
   ],
   "source": [
    "y_valid= Y_Dev['is_click'].values\n",
    "print ('ROC-AUC score using LGB1 is', roc_auc_score(y_valid, preds3))\n",
    "print ('ROC-AUC score using LGB2 is', roc_auc_score(y_valid, preds4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds3 = model3.predict(test_df)\n",
    "preds4 = model4.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = (0.50*preds3+0.50*preds4)\n",
    "\n",
    "out = pd.DataFrame({'id': id_test, 'is_click': preds})\n",
    "out.to_csv(\"pred3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
