{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import xgboost as xgb\n",
    "from time import time\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the train data is  (920871, 14)  Test data is  (773858, 12)  Valid data is (102320, 14)\n"
     ]
    }
   ],
   "source": [
    "#path = '/Users/804357/Desktop/MyFiles/Learn/LOM/Data/'\n",
    "path = '/Users/Vishy/Files/AVDatahack/LOM/Data/' \n",
    "train = pd.read_csv(path+'train.csv')\n",
    "test = pd.read_csv(path+'test.csv')\n",
    "camp = pd.read_csv(path+'campaign_data.csv')\n",
    "\n",
    "train_df = pd.merge(train, camp, on='campaign_id')\n",
    "test_df = pd.merge(test, camp, on='campaign_id')\n",
    "train_df, dev_df = train_test_split(train_df, random_state=42, test_size=0.10)\n",
    "\n",
    "print('Shape of the train data is ',train_df.shape,' Test data is ',test_df.shape,' Valid data is',dev_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_trains = train_df.shape[0]\n",
    "n_devs = dev_df.shape[0]\n",
    "n_tests = test_df.shape[0]\n",
    "\n",
    "full_df = pd.concat([train_df,dev_df,test_df])\n",
    "del train_df,dev_df,test_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New date variable creations\n"
     ]
    }
   ],
   "source": [
    "print('New date variable creations')\n",
    "#train\n",
    "full_df['hour'] = pd.to_datetime(full_df.send_date).dt.hour.astype('uint8')\n",
    "full_df['day'] = pd.to_datetime(full_df.send_date).dt.day.astype('uint8')\n",
    "full_df['dow'] = pd.to_datetime(full_df.send_date).dt.dayofweek.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['campaign_id', 'communication_type', 'email_body', 'email_url',\n",
       "       'id', 'is_click', 'is_open', 'no_of_images',\n",
       "       'no_of_internal_links', 'no_of_sections', 'send_date', 'subject',\n",
       "       'total_links', 'user_id', 'hour', 'day', 'dow'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renaming of the new date variables created\n"
     ]
    }
   ],
   "source": [
    "print('Renaming of the new date variables created')\n",
    "full_df['dow'] = full_df['dow'].map({0:'MON', 1:'TUE', 2:'WED', 3:'THR',4: 'FRI', 5: 'SAT', 6: 'SUN'} ).astype(str)\n",
    "full_df['hour'] = full_df['hour'].map({0:'AM1', 1:'AM1', 2:'AM1', 3:'AM2', 4:'AM2', 5:'AM2', 6:'AM3', 7:'AM3', 8:'AM3',\n",
    "                                         9:'AM4', 10:'AM4', 11:'AM4', 12:'PM1', 13:'PM1', 14:'PM1', 15:'PM2', 16:'PM2',\n",
    "                                         17:'PM2', 18:'PM3', 19:'PM3', 20:'PM3', 21:'PM4', 22:'PM4', 23:'PM4'}).astype(str)\n",
    "full_df['day'] = full_df['day'].map({1:'VEAR', 2:'VEAR', 3:'VEAR', 4:'VEAR', 5:'VEAR', 6:'EAR', 7:'EAR', 8:'EAR',\n",
    "                                       9:'EAR', 10:'EAR', 11:'MID', 12:'MID', 13:'MID', 14:'MID', 15:'MID', 16:'VMID',\n",
    "                                       17:'VMID', 18:'VMID', 19:'VMID', 20:'VMID', 21:'LAT', 22:'LAT', 23:'LAT', \n",
    "                                       24:'LAT', 25:'LAT', 26:'VLAT', 27:'VLAT', 28:'VLAT', 29:'VLAT', 30:'VLAT',\n",
    "                                       31:'VLAT'}).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(920871, 17) (773858, 17) (102320, 17)\n"
     ]
    }
   ],
   "source": [
    "train_df = full_df[:n_trains]\n",
    "dev_df = full_df[n_trains:n_trains+n_devs]\n",
    "test_df = full_df[n_trains+n_devs:]\n",
    "print(train_df.shape,test_df.shape,dev_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouping variables creation for train_data\n",
      "Assigning data types for variables\n"
     ]
    }
   ],
   "source": [
    "print('Grouping variables creation for train_data')\n",
    "# ip - user_id,  Channel - campaign_id\n",
    "\n",
    "# Campaigns per communication\n",
    "gp = train_df[['communication_type','campaign_id']].groupby(by=['communication_type'])[['campaign_id']].count().reset_index().rename(index=str, columns={'campaign_id': 'totcom'})\n",
    "train_df = train_df.merge(gp, on=['communication_type'], how='left')\n",
    "dev_df = dev_df.merge(gp, on=['communication_type'], how='left')\n",
    "test_df = test_df.merge(gp, on=['communication_type'], how='left')\n",
    "del gp\n",
    "gc.collect()\n",
    "# open count per communication\n",
    "gp = train_df[['communication_type','is_open']].groupby(by=['communication_type'])[['is_open']].sum().reset_index().rename(index=str, columns={'is_open': 'opncom'})\n",
    "train_df = train_df.merge(gp, on=['communication_type'], how='left')\n",
    "dev_df = dev_df.merge(gp, on=['communication_type'], how='left')\n",
    "test_df = test_df.merge(gp, on=['communication_type'], how='left')\n",
    "del gp\n",
    "gc.collect()\n",
    "# Click count per communication\n",
    "gp = train_df[['communication_type','is_click']].groupby(by=['communication_type'])[['is_click']].sum().reset_index().rename(index=str, columns={'is_click': 'clkcom'})\n",
    "train_df = train_df.merge(gp, on=['communication_type'], how='left')\n",
    "dev_df = dev_df.merge(gp, on=['communication_type'], how='left')\n",
    "test_df = test_df.merge(gp, on=['communication_type'], how='left')\n",
    "del gp\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "gp = train_df[['communication_type','dow','campaign_id']].groupby(by=['communication_type','dow'])[['campaign_id']].count().reset_index().rename(index=str, columns={'campaign_id': 'totdow'})\n",
    "train_df = train_df.merge(gp, on=['communication_type','dow'], how='left')\n",
    "dev_df = dev_df.merge(gp, on=['communication_type','dow'], how='left')\n",
    "test_df = test_df.merge(gp, on=['communication_type','dow'], how='left')\n",
    "del gp\n",
    "gc.collect()\n",
    "gp = train_df[['communication_type','dow','is_open']].groupby(by=['communication_type','dow'])[['is_open']].sum().reset_index().rename(index=str, columns={'is_open': 'opndow'})\n",
    "train_df = train_df.merge(gp, on=['communication_type','dow'], how='left')\n",
    "dev_df = dev_df.merge(gp, on=['communication_type','dow'], how='left')\n",
    "test_df = test_df.merge(gp, on=['communication_type','dow'], how='left')\n",
    "del gp\n",
    "gc.collect()\n",
    "gp = train_df[['communication_type','dow','is_click']].groupby(by=['communication_type','dow'])[['is_click']].sum().reset_index().rename(index=str, columns={'is_click': 'clkdow'})\n",
    "train_df = train_df.merge(gp, on=['communication_type','dow'], how='left')\n",
    "dev_df = dev_df.merge(gp, on=['communication_type','dow'], how='left')\n",
    "test_df = test_df.merge(gp, on=['communication_type','dow'], how='left')\n",
    "del gp\n",
    "gc.collect()\n",
    "\n",
    "gp = train_df[['communication_type','day','campaign_id']].groupby(by=['communication_type','day'])[['campaign_id']].count().reset_index().rename(index=str, columns={'campaign_id': 'totday'})\n",
    "train_df = train_df.merge(gp, on=['communication_type','day'], how='left')\n",
    "dev_df = dev_df.merge(gp, on=['communication_type','day'], how='left')\n",
    "test_df = test_df.merge(gp, on=['communication_type','day'], how='left')\n",
    "del gp\n",
    "gc.collect()\n",
    "gp = train_df[['communication_type','day','is_open']].groupby(by=['communication_type','day'])[['is_open']].sum().reset_index().rename(index=str, columns={'is_open': 'opnday'})\n",
    "train_df = train_df.merge(gp, on=['communication_type','day'], how='left')\n",
    "dev_df = dev_df.merge(gp, on=['communication_type','day'], how='left')\n",
    "test_df = test_df.merge(gp, on=['communication_type','day'], how='left')\n",
    "del gp\n",
    "gc.collect()\n",
    "gp = train_df[['communication_type','day','is_click']].groupby(by=['communication_type','day'])[['is_click']].sum().reset_index().rename(index=str, columns={'is_click': 'clkday'})\n",
    "train_df = train_df.merge(gp, on=['communication_type','day'], how='left')\n",
    "dev_df = dev_df.merge(gp, on=['communication_type','day'], how='left')\n",
    "test_df = test_df.merge(gp, on=['communication_type','day'], how='left')\n",
    "del gp\n",
    "gc.collect()\n",
    "\n",
    "gp = train_df[['communication_type','hour','campaign_id']].groupby(by=['communication_type','hour'])[['campaign_id']].count().reset_index().rename(index=str, columns={'campaign_id': 'tothour'})\n",
    "train_df = train_df.merge(gp, on=['communication_type','hour'], how='left')\n",
    "dev_df = dev_df.merge(gp, on=['communication_type','hour'], how='left')\n",
    "test_df = test_df.merge(gp, on=['communication_type','hour'], how='left')\n",
    "del gp\n",
    "gc.collect()\n",
    "\n",
    "gp = train_df[['communication_type','hour','is_open']].groupby(by=['communication_type','hour'])[['is_open']].sum().reset_index().rename(index=str, columns={'is_open': 'opnhour'})\n",
    "train_df = train_df.merge(gp, on=['communication_type','hour'], how='left')\n",
    "dev_df = dev_df.merge(gp, on=['communication_type','hour'], how='left')\n",
    "test_df = test_df.merge(gp, on=['communication_type','hour'], how='left')\n",
    "del gp\n",
    "gc.collect()\n",
    "\n",
    "gp = train_df[['communication_type','hour','is_click']].groupby(by=['communication_type','hour'])[['is_click']].sum().reset_index().rename(index=str, columns={'is_click': 'clkhour'})\n",
    "train_df = train_df.merge(gp, on=['communication_type','hour'], how='left')\n",
    "dev_df = dev_df.merge(gp, on=['communication_type','hour'], how='left')\n",
    "test_df = test_df.merge(gp, on=['communication_type','hour'], how='left')\n",
    "del gp\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Assigning data types for Training variables\")\n",
    "train_df['totcom'] = train_df['totcom'].fillna(0).astype('uint16')\n",
    "train_df['opncom'] = train_df['opncom'].fillna(0).astype('uint16')\n",
    "train_df['clkcom'] = train_df['clkcom'].fillna(0).astype('uint16')\n",
    "train_df['opncomrate'] = ((train_df['opncom']/train_df['totcom']).replace(np.inf, 0))\n",
    "train_df['clkcomrate'] = ((train_df['clkcom']/train_df['totcom']).replace(np.inf, 0))\n",
    "\n",
    "train_df['totdow'] = train_df['totdow'].fillna(0).astype('uint16')\n",
    "train_df['opndow'] = train_df['opndow'].fillna(0).astype('uint16')\n",
    "train_df['clkdow'] = train_df['clkdow'].fillna(0).astype('uint16')\n",
    "train_df['opndowrate'] = ((train_df['opndow']/train_df['totdow']).replace(np.inf, 0))\n",
    "train_df['clkdowrate'] = ((train_df['clkdow']/train_df['totdow']).replace(np.inf, 0))\n",
    "\n",
    "train_df['totday'] = train_df['totday'].fillna(0).astype('uint16')\n",
    "train_df['opnday'] = train_df['opnday'].fillna(0).astype('uint16')\n",
    "train_df['clkday'] = train_df['clkday'].fillna(0).astype('uint16')\n",
    "train_df['opndayrate'] = ((train_df['opnday']/train_df['totday']).replace(np.inf, 0))\n",
    "train_df['clkdayrate'] = ((train_df['clkday']/train_df['totday']).replace(np.inf, 0))\n",
    "\n",
    "train_df['tothour'] = train_df['tothour'].fillna(0).astype('uint16')\n",
    "train_df['opnhour'] = train_df['opnhour'].fillna(0).astype('uint16')\n",
    "train_df['clkhour'] = train_df['clkhour'].fillna(0).astype('uint16')\n",
    "train_df['opnhourrate'] = ((train_df['opnhour']/train_df['tothour']).replace(np.inf, 0))\n",
    "train_df['clkhourrate'] = ((train_df['clkhour']/train_df['tothour']).replace(np.inf, 0))\n",
    "\n",
    "del train_df['totcom'],train_df['opncom'],train_df['clkcom'],train_df['totdow'],train_df['opndow'],train_df['clkdow']\n",
    "del train_df['totday'],train_df['opnday'],train_df['clkday'],train_df['tothour'],train_df['opnhour'],train_df['clkhour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df['totcom'] = dev_df['totcom'].fillna(0).astype('uint16')\n",
    "dev_df['opncom'] = dev_df['opncom'].fillna(0).astype('uint16')\n",
    "dev_df['clkcom'] = dev_df['clkcom'].fillna(0).astype('uint16')\n",
    "dev_df['opncomrate'] = ((dev_df['opncom']/dev_df['totcom']).replace(np.inf, 0))\n",
    "dev_df['clkcomrate'] = ((dev_df['clkcom']/dev_df['totcom']).replace(np.inf, 0))\n",
    "\n",
    "dev_df['totdow'] = dev_df['totdow'].fillna(0).astype('uint16')\n",
    "dev_df['opndow'] = dev_df['opndow'].fillna(0).astype('uint16')\n",
    "dev_df['clkdow'] = dev_df['clkdow'].fillna(0).astype('uint16')\n",
    "dev_df['opndowrate'] = ((dev_df['opndow']/dev_df['totdow']).replace(np.inf, 0))\n",
    "dev_df['clkdowrate'] = ((dev_df['clkdow']/dev_df['totdow']).replace(np.inf, 0))\n",
    "\n",
    "dev_df['totday'] = dev_df['totday'].fillna(0).astype('uint16')\n",
    "dev_df['opnday'] = dev_df['opnday'].fillna(0).astype('uint16')\n",
    "dev_df['clkday'] = dev_df['clkday'].fillna(0).astype('uint16')\n",
    "dev_df['opndayrate'] = ((dev_df['opnday']/dev_df['totday']).replace(np.inf, 0))\n",
    "dev_df['clkdayrate'] = ((dev_df['clkday']/dev_df['totday']).replace(np.inf, 0))\n",
    "\n",
    "dev_df['tothour'] = dev_df['tothour'].fillna(0).astype('uint16')\n",
    "dev_df['opnhour'] = dev_df['opnhour'].fillna(0).astype('uint16')\n",
    "dev_df['clkhour'] = dev_df['clkhour'].fillna(0).astype('uint16')\n",
    "dev_df['opnhourrate'] = ((dev_df['opnhour']/dev_df['tothour']).replace(np.inf, 0))\n",
    "dev_df['clkhourrate'] = ((dev_df['clkhour']/dev_df['tothour']).replace(np.inf, 0))\n",
    "\n",
    "del dev_df['totcom'],dev_df['opncom'],dev_df['clkcom'],dev_df['totdow'],dev_df['opndow'],dev_df['clkdow']\n",
    "del dev_df['totday'],dev_df['opnday'],dev_df['clkday'],dev_df['tothour'],dev_df['opnhour'],dev_df['clkhour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['totcom'] = test_df['totcom'].fillna(0).astype('uint16')\n",
    "test_df['opncom'] = test_df['opncom'].fillna(0).astype('uint16')\n",
    "test_df['clkcom'] = test_df['clkcom'].fillna(0).astype('uint16')\n",
    "test_df['opncomrate'] = ((test_df['opncom']/test_df['totcom']).replace(np.inf, 0))\n",
    "test_df['clkcomrate'] = ((test_df['clkcom']/test_df['totcom']).replace(np.inf, 0))\n",
    "\n",
    "test_df['totdow'] = test_df['totdow'].fillna(0).astype('uint16')\n",
    "test_df['opndow'] = test_df['opndow'].fillna(0).astype('uint16')\n",
    "test_df['clkdow'] = test_df['clkdow'].fillna(0).astype('uint16')\n",
    "test_df['opndowrate'] = ((test_df['opndow']/test_df['totdow']).replace(np.inf, 0))\n",
    "test_df['clkdowrate'] = ((test_df['clkdow']/test_df['totdow']).replace(np.inf, 0))\n",
    "\n",
    "test_df['totday'] = test_df['totday'].fillna(0).astype('uint16')\n",
    "test_df['opnday'] = test_df['opnday'].fillna(0).astype('uint16')\n",
    "test_df['clkday'] = test_df['clkday'].fillna(0).astype('uint16')\n",
    "test_df['opndayrate'] = ((test_df['opnday']/test_df['totday']).replace(np.inf, 0))\n",
    "test_df['clkdayrate'] = ((test_df['clkday']/test_df['totday']).replace(np.inf, 0))\n",
    "\n",
    "test_df['tothour'] = test_df['tothour'].fillna(0).astype('uint16')\n",
    "test_df['opnhour'] = test_df['opnhour'].fillna(0).astype('uint16')\n",
    "test_df['clkhour'] = test_df['clkhour'].fillna(0).astype('uint16')\n",
    "test_df['opnhourrate'] = ((test_df['opnhour']/test_df['tothour']).replace(np.inf, 0))\n",
    "test_df['clkhourrate'] = ((test_df['clkhour']/test_df['tothour']).replace(np.inf, 0))\n",
    "\n",
    "del test_df['totcom'],test_df['opncom'],test_df['clkcom'],test_df['totdow'],test_df['opndow'],test_df['clkdow']\n",
    "del test_df['totday'],test_df['opnday'],test_df['clkday'],test_df['tothour'],test_df['opnhour'],test_df['clkhour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['campaign_id', 'communication_type', 'email_body', 'email_url', 'id',\n",
       "       'is_click', 'is_open', 'no_of_images', 'no_of_internal_links',\n",
       "       'no_of_sections', 'send_date', 'subject', 'total_links', 'user_id',\n",
       "       'hour', 'day', 'dow', 'totcnt', 'opncnt', 'clkcnt', 'dowcnt', 'dowclk',\n",
       "       'daycnt', 'dayclk', 'hourcnt', 'hourclk'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1023191, 13) (773858, 13)\n"
     ]
    }
   ],
   "source": [
    "# prep data for Base Model\n",
    "target_train = train_df['is_click']\n",
    "id_test = test_df['id']\n",
    "\n",
    "del train['campaign_id'],train['id'],train['user_id'],train['is_open'],train['is_click'],train['email_body'],train['subject'],train['email_url'],train['send_date'],train['no_of_images'],train['no_of_internal_links'],train['no_of_sections'],train['total_links']\n",
    "del test['campaign_id'],test['id'],test['user_id'],test['is_open'],test['is_click'],test['email_body'],test['subject'],test['email_url'],test['send_date'],test['no_of_images'],test['no_of_internal_links'],test['no_of_sections'],test['total_links']\n",
    "\n",
    "print(train.shape,test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1023191, 29) (773858, 27)\n"
     ]
    }
   ],
   "source": [
    "train_cats = pd.get_dummies(data=train, columns=['communication_type','dow','hour','day'], drop_first=True)\n",
    "test_cats = pd.get_dummies(data=test, columns=['communication_type','dow','hour','day'], drop_first=True)\n",
    "print (train_cats.shape,test_cats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['totcnt', 'opncnt', 'clkcnt', 'dowcnt', 'dowclk', 'daycnt', 'dayclk',\n",
       "       'hourcnt', 'hourclk', 'communication_type_Corporate',\n",
       "       'communication_type_Hackathon', 'communication_type_Newsletter',\n",
       "       'communication_type_Others', 'communication_type_Upcoming Events',\n",
       "       'communication_type_Webinar', 'dow_Mon', 'dow_Sat', 'dow_Sun',\n",
       "       'dow_Thr', 'dow_Tue', 'dow_Wed', 'hour_PM1', 'hour_PM2', 'hour_PM3',\n",
       "       'hour_PM4', 'day_LAT', 'day_MID', 'day_VLAT', 'day_VMID'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cats.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "listA = list(train_cats.columns.values)\n",
    "listB = list(test_cats.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "communication_type_Corporate\n",
      "communication_type_Others\n",
      "communication_type_Webinar\n",
      "day_LAT\n",
      "day_VLAT\n"
     ]
    }
   ],
   "source": [
    "for item in listA:\n",
    "    if item not in listB:\n",
    "        print (item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hour_AM3\n",
      "hour_AM4\n",
      "day_VEAR\n"
     ]
    }
   ],
   "source": [
    "for item in listB:\n",
    "    if item not in listA:\n",
    "        print (item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cats['communication_type_Corporate'],test_cats['communication_type_Others'],test_cats['communication_type_Webinar'],test_cats['day_LAT'],test_cats['day_VLAT']=0,0,0,0,0\n",
    "train_cats['hour_AM3'],train_cats['hour_AM4'],train_cats['hour_AM4'] =0,0,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['totcnt', 'opncnt', 'clkcnt', 'dowcnt', 'dowclk', 'daycnt', 'dayclk',\n",
       "       'hourcnt', 'hourclk', 'communication_type_Corporate',\n",
       "       'communication_type_Hackathon', 'communication_type_Newsletter',\n",
       "       'communication_type_Others', 'communication_type_Upcoming Events',\n",
       "       'communication_type_Webinar', 'dow_Mon', 'dow_Sat', 'dow_Sun',\n",
       "       'dow_Thr', 'dow_Tue', 'dow_Wed', 'hour_PM1', 'hour_PM2', 'hour_PM3',\n",
       "       'hour_PM4', 'day_LAT', 'day_MID', 'day_VLAT', 'day_VMID', 'hour_AM3',\n",
       "       'hour_AM4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cats.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cats = train_cats[['totcnt', 'opncnt', 'clkcnt', 'dowcnt', 'dowclk', 'daycnt', 'dayclk','hourcnt', 'hourclk',\n",
    "                        'communication_type_Corporate','communication_type_Hackathon','communication_type_Newsletter',\n",
    "                        'communication_type_Others','communication_type_Upcoming Events','communication_type_Webinar',\n",
    "                        'dow_Mon', 'dow_Sat', 'dow_Sun','dow_Thr', 'dow_Tue', 'dow_Wed', 'hour_PM1', 'hour_PM2',\n",
    "                        'hour_PM3','hour_PM4', 'day_LAT', 'day_MID', 'day_VLAT', 'day_VMID', 'hour_AM3','hour_AM4']]\n",
    "\n",
    "test_cats = test_cats[['totcnt', 'opncnt', 'clkcnt', 'dowcnt', 'dowclk', 'daycnt', 'dayclk','hourcnt', 'hourclk',\n",
    "                      'communication_type_Corporate','communication_type_Hackathon','communication_type_Newsletter',\n",
    "                      'communication_type_Others','communication_type_Upcoming Events','communication_type_Webinar',\n",
    "                      'dow_Mon', 'dow_Sat', 'dow_Sun','dow_Thr', 'dow_Tue', 'dow_Wed', 'hour_PM1', 'hour_PM2',\n",
    "                      'hour_PM3','hour_PM4', 'day_LAT', 'day_MID', 'day_VLAT', 'day_VMID', 'hour_AM3','hour_AM4']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = np.array(train_cats)\n",
    "testdf = np.array(test_cats)\n",
    "\n",
    "xgb_preds = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "kf = KFold(n_splits = K, random_state = 42, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-21-a6849180cd34>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-21-a6849180cd34>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    xgb_params = {'eta': 0.02, 'objective': 'binary:logistic', max_depth= 6, subsample = 1, colsample_bytree = 1,\u001b[0m\n\u001b[0m                                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "for train_index, test_index in kf.split(traindf):\n",
    "    train_X, valid_X = traindf[train_index], traindf[test_index]\n",
    "    train_y, valid_y = target_train[train_index], target_train[test_index]\n",
    "\n",
    "    # params configuration also from the1owl's kernel\n",
    "    # https://www.kaggle.com/the1owl/forza-baseline\n",
    "    xgb_params = {'eta': 0.02, 'objective': 'binary:logistic', max_depth= 6, subsample = 1, colsample_bytree = 1,\n",
    "                  min_chil_weight=1, 'eval_metric': 'auc', 'seed': 42, 'silent': True}\n",
    "\n",
    "    d_train = xgb.DMatrix(train_X, train_y)\n",
    "    d_valid = xgb.DMatrix(valid_X, valid_y)\n",
    "    d_test = xgb.DMatrix(testdf)\n",
    "    \n",
    "    watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "    model = xgb.train(xgb_params, d_train, 5000,  watchlist, \n",
    "                      maximize=True, verbose_eval=50, early_stopping_rounds=50)\n",
    "                        \n",
    "    xgb_pred = model.predict(d_test)\n",
    "    xgb_preds.append(list(xgb_pred))\n",
    "\n",
    "end = time()\n",
    "print ('Time taken is:', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=[]\n",
    "for i in range(len(xgb_preds[0])):\n",
    "    sum=0\n",
    "    for j in range(K):\n",
    "        sum+=xgb_preds[j][i]\n",
    "    preds.append(sum / K)\n",
    "\n",
    "out = pd.DataFrame({'id': id_test, 'is_click': preds})\n",
    "out.to_csv(\"pred3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
