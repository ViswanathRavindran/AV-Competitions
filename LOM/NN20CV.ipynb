{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os; os.environ['OMP_NUM_THREADS'] = '1'\n",
    "from contextlib import contextmanager\n",
    "from functools import partial\n",
    "from operator import itemgetter\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import time\n",
    "from typing import List, Dict\n",
    "\n",
    "import keras as ks\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer as Tfidf\n",
    "from sklearn.pipeline import make_pipeline, make_union, Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(f'[{name}] done in {time.time() - t0:.0f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df['hour'] = pd.to_datetime(df.send_date).dt.hour.astype('uint8')\n",
    "    df['day'] = pd.to_datetime(df.send_date).dt.day.astype('uint8')\n",
    "    df['dow'] = pd.to_datetime(df.send_date).dt.dayofweek.astype('uint8')\n",
    "    print('DateTime Converted')\n",
    "    df['dow'] = df['dow'].map({0:'MON',1:'TUE',2:'WED',3:'THR',4:'FRI',5:'SAT',6:'SUN'} ).astype(str)\n",
    "    df['hour'] = df['hour'].map({0:'AM1',1:'AM1',2:'AM1',3:'AM2',4:'AM2',5:'AM2',6:'AM3',7:'AM3',8:'AM3',9:'AM4',10:'AM4',\n",
    "                                 11:'AM4',12:'PM1',13:'PM1',14:'PM1',15:'PM2',16:'PM2',17:'PM2',18:'PM3',19:'PM3',20:'PM3',\n",
    "                                 21:'PM4',22:'PM4',23:'PM4'}).astype(str)\n",
    "    df['day'] = df['day'].map({1:'VEAR',2:'VEAR',3:'VEAR',4:'VEAR',5:'VEAR',6:'EAR',7:'EAR',8:'EAR',9:'EAR',10:'EAR',11:'MID',\n",
    "                               12:'MID',13:'MID',14:'MID',15:'MID',16:'VMID',17:'VMID',18:'VMID',19:'VMID',20:'VMID',21:'LAT',\n",
    "                               22:'LAT',23:'LAT',24:'LAT',25:'LAT',26:'VLAT',27:'VLAT',28:'VLAT',29:'VLAT',30:'VLAT',\n",
    "                               31:'VLAT'}).astype(str)\n",
    "    df['time'] = df['hour'].fillna('')+ ' ' + df['day'].fillna('')+' ' + df['dow'].fillna('')\n",
    "    df['subject'] = (df['communication_type']+' '+df['subject'].fillna(''))\n",
    "    df['email_body'] = ( df['communication_type']+' '+df['email_body'].fillna(''))\n",
    "    return df[['time','subject','email_body','communication_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_field(f: str, *vec) -> Pipeline:\n",
    "    return make_pipeline(FunctionTransformer(itemgetter(f), validate=False), *vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_records(df: pd.DataFrame) -> List[Dict]:\n",
    "    return df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict(xs, y_train) -> np.ndarray:\n",
    "    X_train, X_test = xs\n",
    "    config = tf.ConfigProto(intra_op_parallelism_threads=1, use_per_session_threads=1, inter_op_parallelism_threads=1)\n",
    "    with tf.Session(graph=tf.Graph(), config=config) as sess, timer('fit_predict'):\n",
    "        ks.backend.set_session(sess)\n",
    "        model_in = ks.Input(shape=(X_train.shape[1],), dtype='float32', sparse=True)\n",
    "        out = ks.layers.Dense(192, activation='relu')(model_in)\n",
    "        out = ks.layers.Dense(64, activation='relu')(out)\n",
    "        out = ks.layers.Dense(64, activation='relu')(out)\n",
    "        out = ks.layers.Dense(1, activation='sigmoid')(out)\n",
    "        model = Model(model_in, out)\n",
    "        model.compile(loss='binary_crossentropy', optimizer=ks.optimizers.Adam(lr=3e-3))\n",
    "        for i in range(3):\n",
    "            with timer(f'epoch {i + 1}'):\n",
    "                model.fit(x=X_train, y=y_train, batch_size=2**(5 + i), epochs=1, verbose=1)\n",
    "        return model.predict(X_test)[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Imported\n",
      "Starting Data preprocessing\n",
      "DateTime Converted\n"
     ]
    },
    {
     "ename": "MaybeEncodingError",
     "evalue": "Error sending result: '[(<972031x3913 sparse matrix of type '<class 'numpy.float64'>'\n\twith 257739443 stored elements in Compressed Sparse Row format>, Pipeline(memory=None,\n     steps=[('functiontransformer', FunctionTransformer(accept_sparse=False,\n          func=operator.itemgetter('email_body'), inv_kw_args=None,\n          inverse_func=None, kw_args=None, pass_y='deprecated',\n          validate=False)), ('tfidfvectorizer', TfidfVectorizer(analyzer='word', binary=False, d...ear_tf=False,\n        token_pattern='\\\\w+', tokenizer=None, use_idf=True,\n        vocabulary=None))]))]'. Reason: 'error(\"'i' format requires -2147483648 <= number <= 2147483647\",)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMaybeEncodingError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-caac377c521f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-caac377c521f>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is_click'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Starting Data preprocessing'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'X_train: {X_train.shape} of {X_train.dtype}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    737\u001b[0m             delayed(_fit_transform_one)(trans, weight, X, y,\n\u001b[1;32m    738\u001b[0m                                         **fit_params)\n\u001b[0;32m--> 739\u001b[0;31m             for name, trans, weight in self._iter())\n\u001b[0m\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMaybeEncodingError\u001b[0m: Error sending result: '[(<972031x3913 sparse matrix of type '<class 'numpy.float64'>'\n\twith 257739443 stored elements in Compressed Sparse Row format>, Pipeline(memory=None,\n     steps=[('functiontransformer', FunctionTransformer(accept_sparse=False,\n          func=operator.itemgetter('email_body'), inv_kw_args=None,\n          inverse_func=None, kw_args=None, pass_y='deprecated',\n          validate=False)), ('tfidfvectorizer', TfidfVectorizer(analyzer='word', binary=False, d...ear_tf=False,\n        token_pattern='\\\\w+', tokenizer=None, use_idf=True,\n        vocabulary=None))]))]'. Reason: 'error(\"'i' format requires -2147483648 <= number <= 2147483647\",)'"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    vectorizer = make_union(on_field('subject', Tfidf(max_features=100000, token_pattern='\\w+')),\n",
    "                            on_field('email_body', Tfidf(max_features=100000, token_pattern='\\w+', ngram_range=(1, 2))),\n",
    "                            on_field('communication_type', Tfidf(max_features=10,token_pattern='\\w+', ngram_range=(1), binary=True),\n",
    "                            on_field('time', TFidf(max_feature=100, token_pattern='\\w+', ngram_range=(1,3), binary=True)),\n",
    "                            n_jobs=4)\n",
    "    #y_scaler = StandardScaler()\n",
    "    with timer('process train'):\n",
    "        #path = '/Users/804357/Desktop/MyFiles/Learn/LOM/Data/'\n",
    "        path = '/Users/Vishy/Files/AVDatahack/LOM/Data/' \n",
    "        limtrain = pd.read_csv(path+'train.csv')\n",
    "        #limtest = pd.read_csv(path+'test.csv')\n",
    "        camp = pd.read_csv(path+'campaign_data.csv')\n",
    "        train = pd.merge(limtrain, camp, on='campaign_id')\n",
    "        #test = pd.merge(limtest, camp, on='campaign_id')\n",
    "        del limtrain, camp\n",
    "        print('Data Imported')\n",
    "        cv = KFold(n_splits=20, shuffle=True, random_state=42)\n",
    "        train_ids, valid_ids = next(cv.split(train))\n",
    "        train, valid = train.iloc[train_ids], train.iloc[valid_ids]\n",
    "        y_train = (train['is_click'].values.reshape(-1, 1))\n",
    "        print('Starting Data preprocessing')\n",
    "        X_train = vectorizer.fit_transform(preprocess(train)).astype(np.float32)\n",
    "        print(f'X_train: {X_train.shape} of {X_train.dtype}')\n",
    "        del train\n",
    "    with timer('process valid'):\n",
    "        X_valid = vectorizer.transform(preprocess(valid)).astype(np.float32)\n",
    "    with ThreadPool(processes=4) as pool:\n",
    "        Xb_train, Xb_valid = [x.astype(np.bool).astype(np.float32) for x in [X_train, X_valid]]\n",
    "        xs = [[Xb_train, Xb_valid], [X_train, X_valid]] * 2\n",
    "        y_pred = np.mean(pool.map(partial(fit_predict, y_train=y_train), xs), axis=0)\n",
    "    y_pred = (y_pred.reshape(-1, 1))[:, 0]\n",
    "    print('Valid AUC-ROC: {:.4f}'.format(roc_auc_score(valid['is_click'], y_pred)))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
